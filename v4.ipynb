{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Best score is coming at missing -999, non-normalised, > 96% dropping features : 66% something"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.decomposition import TruncatedSVD, PCA, FastICA\n",
    "from sklearn.random_projection import GaussianRandomProjection, SparseRandomProjection\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.pipeline import make_pipeline, make_union\n",
    "from sklearn.manifold import TSNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', 1000)\n",
    "pd.set_option('display.max_rows', 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('train_iI26erW/train.csv', 'r') as fp, open('test_plBmD8c.csv') as fg:\n",
    "    train = pd.read_csv(fp)\n",
    "    test = pd.read_csv(fg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(train.shape)\n",
    "print(test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## count no. of NA per row\n",
    "\n",
    "train['na_count'] = train.isnull().sum(axis=1)\n",
    "test['na_count'] = test.isnull().sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## net balance after spending in mon 1\n",
    "addCols = [x for x in train.columns if 'CARD_' in x]\n",
    "train['add_spend_mon1'] = train[addCols].sum(axis = 1) \n",
    "test['add_spend_mon1'] = test[addCols].sum(axis = 1)\n",
    "\n",
    "train['add_spend_mon1'] = train['add_spend_mon1'].map(lambda x: x.count('Y'))\n",
    "test['add_spend_mon1'] = test['add_spend_mon1'].map(lambda x: x.count('Y'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train['CLOSED_DATE'] = train['CLOSED_DATE'].astype(str)\n",
    "test['CLOSED_DATE'] = test['CLOSED_DATE'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def getDateFormat(val):\n",
    "    if not val == 'nan':\n",
    "        try:\n",
    "            a = datetime.strptime(val, '%d%b%Y')\n",
    "            b = a.strftime('%Y-%m-%d')\n",
    "            return b\n",
    "        except TypeError:\n",
    "            return np.nan\n",
    "    else:\n",
    "        return np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "train['closed_date_format'] = train['CLOSED_DATE'].map(getDateFormat)\n",
    "test['closed_date_format'] = test['CLOSED_DATE'].map(getDateFormat)\n",
    "\n",
    "train['maturity_gl_format'] = train['MATURITY_GL'].map(getDateFormat)\n",
    "test['maturity_gl_format'] = test['MATURITY_GL'].map(getDateFormat)\n",
    "\n",
    "train['maturity_lap_format'] = train['MATURITY_LAP'].map(getDateFormat)\n",
    "test['maturity_lap_format'] = test['MATURITY_LAP'].map(getDateFormat)\n",
    "\n",
    "train['maturity_las_format'] = train['MATURITY_LAS'].map(getDateFormat)\n",
    "test['maturity_las_format'] = test['MATURITY_LAS'].map(getDateFormat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## drop date formats\n",
    "train.drop(['CLOSED_DATE','MATURITY_GL','MATURITY_LAP','MATURITY_LAS'], axis=1, inplace=True)\n",
    "test.drop(['CLOSED_DATE','MATURITY_GL','MATURITY_LAP','MATURITY_LAS'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## date features\n",
    "\n",
    "train['closed_date_format'] = pd.to_datetime(train['closed_date_format'])\n",
    "test['closed_date_format'] = pd.to_datetime(test['closed_date_format'])\n",
    "\n",
    "train['maturity_gl_format'] = pd.to_datetime(train['maturity_gl_format'])\n",
    "test['maturity_gl_format'] = pd.to_datetime(test['maturity_gl_format'])\n",
    "\n",
    "train['maturity_lap_format'] = pd.to_datetime(train['maturity_lap_format'])\n",
    "test['maturity_lap_format'] = pd.to_datetime(test['maturity_lap_format'])\n",
    "\n",
    "train['maturity_las_format'] = pd.to_datetime(train['maturity_las_format'])\n",
    "test['maturity_las_format'] = pd.to_datetime(test['maturity_las_format'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train['closed_date_weekday'] = train['closed_date_format'].dt.weekday\n",
    "test['closed_date_weekday'] = test['closed_date_format'].dt.weekday\n",
    "\n",
    "train['closed_date_year'] = train['closed_date_format'].dt.year\n",
    "test['closed_date_year'] = test['closed_date_format'].dt.year\n",
    "\n",
    "train['closed_date_month'] = train['closed_date_format'].dt.month\n",
    "test['closed_date_month'] = test['closed_date_format'].dt.month\n",
    "\n",
    "train['closed_date_day'] = train['closed_date_format'].dt.day\n",
    "test['closed_date_day'] = test['closed_date_format'].dt.day\n",
    "\n",
    "#########################################################\n",
    "\n",
    "train['maturity_gl_weekday'] = train['maturity_gl_format'].dt.weekday\n",
    "test['maturity_gl_weekday'] = test['maturity_gl_format'].dt.weekday\n",
    "\n",
    "train['maturity_gl_year'] = train['maturity_gl_format'].dt.year\n",
    "test['maturity_gl_year'] = test['maturity_gl_format'].dt.year\n",
    "\n",
    "train['maturity_gl_month'] = train['maturity_gl_format'].dt.month\n",
    "test['maturity_gl_month'] = test['maturity_gl_format'].dt.month\n",
    "\n",
    "train['maturity_gl_day'] = train['maturity_gl_format'].dt.day\n",
    "test['maturity_gl_day'] = test['maturity_gl_format'].dt.day\n",
    "\n",
    "################################################################\n",
    "\n",
    "train['maturity_lap_weekday'] = train['maturity_lap_format'].dt.weekday\n",
    "test['maturity_lap_weekday'] = test['maturity_lap_format'].dt.weekday\n",
    "\n",
    "train['maturity_lap_year'] = train['maturity_lap_format'].dt.year\n",
    "test['maturity_lap_year'] = test['maturity_lap_format'].dt.year\n",
    "\n",
    "train['maturity_lap_month'] = train['maturity_lap_format'].dt.month\n",
    "test['maturity_lap_month'] = test['maturity_lap_format'].dt.month\n",
    "\n",
    "train['maturity_lap_day'] = train['maturity_lap_format'].dt.day\n",
    "test['maturity_lap_day'] = test['maturity_lap_format'].dt.day\n",
    "\n",
    "######################################################################\n",
    "\n",
    "train['maturity_las_weekday'] = train['maturity_las_format'].dt.weekday\n",
    "test['maturity_las_weekday'] = test['maturity_las_format'].dt.weekday\n",
    "\n",
    "train['maturity_las_year'] = train['maturity_las_format'].dt.year\n",
    "test['maturity_las_year'] = test['maturity_las_format'].dt.year\n",
    "\n",
    "train['maturity_las_month'] = train['maturity_las_format'].dt.month\n",
    "test['maturity_las_month'] = test['maturity_las_format'].dt.month\n",
    "\n",
    "train['maturity_las_day'] = train['maturity_las_format'].dt.day\n",
    "test['maturity_las_day'] = test['maturity_las_format'].dt.day\n",
    "\n",
    "######################################################################\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "formatCols = [x for x in train.columns if  '_format' in x]\n",
    "train.drop(formatCols, axis=1, inplace=True)\n",
    "test.drop(formatCols, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train['net_emi_paid'] = train['HL_EMI'] / train['SCRUB_EMI']\n",
    "test['net_emi_paid'] = test['HL_EMI'] / test['SCRUB_EMI']\n",
    "\n",
    "train['total_salary_credited'] = train['SAL_MON_01'] + train['SAL_MON_02'] + train['SAL_MON_03']\n",
    "test['total_salary_credited'] = test['SAL_MON_01'] + test['SAL_MON_02'] + test['SAL_MON_03']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train['total_balance'] = train['EOP_MON_02'] + train['EOP_MON_03'] + train['EOP_BAL_MON_01']\n",
    "test['total_balance'] =  test['EOP_MON_02'] + test['EOP_MON_03'] + test['EOP_BAL_MON_01']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cardCols = [x for x in train.columns if 'CARD_' in x]\n",
    "\n",
    "for x in cardCols:\n",
    "    train[x] = train[x].map(lambda x: 1 if x == 'Y' else 0)\n",
    "    test[x] = test[x].map(lambda x: 1 if x == 'Y' else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train['spent_sum'] = train[cardCols].sum(axis=1)\n",
    "test['spent_sum'] = test[cardCols].sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dcount = [x for x in train.columns if 'D_COUNT' in x]\n",
    "ccount = [x for x in train.columns if 'C_COUNT' in x]\n",
    "\n",
    "train['debit_count'] = train[dcount].sum(axis=1)\n",
    "train['credit_count'] = train[ccount].sum(axis=1)\n",
    "\n",
    "test['debit_count'] = test[dcount].sum(axis=1)\n",
    "test['credit_count'] = test[ccount].sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "damount = [x for x in train.columns if 'D_AMT' in x]\n",
    "camount = [x for x in train.columns if 'C_AMT' in x]\n",
    "\n",
    "train['debit_amount'] = train[damount].sum(axis=1)\n",
    "train['credit_amount'] = train[camount].sum(axis=1)\n",
    "\n",
    "test['debit_amount'] = test[damount].sum(axis=1)\n",
    "test['credit_amount'] = test[camount].sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train['DESIGNATION_FINAL'] = train['DESIGNATION_FINAL'].map(lambda x: np.nan if x == 'MISSING' else x)\n",
    "test['DESIGNATION_FINAL'] = test['DESIGNATION_FINAL'].map(lambda x: np.nan if x == 'MISSING' else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dest_tr = pd.get_dummies(train['DESIGNATION_FINAL'])\n",
    "det_te = pd.get_dummies(test['DESIGNATION_FINAL'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = pd.concat([train, dest_tr], axis=1)\n",
    "test = pd.concat([test, det_te], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train.drop('DESIGNATION_FINAL', axis=1, inplace=True)\n",
    "test.drop('DESIGNATION_FINAL', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ccspend = sorted([x for x in train.columns if 'CC_SPEND' in x])\n",
    "dcspend = sorted([x for x in train.columns if 'DC_SPEND' in x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train['credit_spent'] = train['CC_SPEND_MON_01'] + train['CC_SPEND_MON_02'] + train['CC_SPEND_MON_03'] +train['CC_SPEND_MON_04'] + train['CC_SPEND_MON_05'] + train['CC_SPEND_MON_06'] \n",
    "test['credit_spent'] = test['CC_SPEND_MON_01'] + test['CC_SPEND_MON_02'] + test['CC_SPEND_MON_03'] + test['CC_SPEND_MON_04'] + test['CC_SPEND_MON_05'] + test['CC_SPEND_MON_06'] \n",
    "\n",
    "train['debit_spent'] = train['DC_SPEND_MON_01'] + train['DC_SPEND_MON_02'] + train['DC_SPEND_MON_03'] +train['DC_SPEND_MON_04'] + train['DC_SPEND_MON_05'] + train['DC_SPEND_MON_06'] \n",
    "test['debit_spent'] = test['DC_SPEND_MON_01'] + test['DC_SPEND_MON_02'] + test['DC_SPEND_MON_03'] +test['DC_SPEND_MON_04'] + test['DC_SPEND_MON_05'] + test['DC_SPEND_MON_06'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cats= ['_ATM', '_CARE', '_ENT', '_HBY', '_HMD', '_HTL', '_JER', '_MED', '_RST', '_TRL']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## total sum by categories\n",
    "for i in ccspend:\n",
    "    for j in cats:\n",
    "        p = []\n",
    "        if i.endswith(j):\n",
    "            p.append(i)\n",
    "        train['cc_sum_'+j] = train[p].sum(axis=1)\n",
    "        test['cc_sum_'+j] = test[p].sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## total sum by debit category\n",
    "for i in dcspend:\n",
    "    for j in cats:\n",
    "        p = []\n",
    "        if i.endswith(j):\n",
    "            p.append(i)\n",
    "        train['dc_sum_'+j] = train[p].sum(axis=1)\n",
    "        test['dc_sum_'+j] = test[p].sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## total credit spent is greater than credit limit\n",
    "\n",
    "train['is_exceed_credit'] = train.apply(lambda row: 1 if (row['STMT_MON_01'] + row['STMT_MON_02'] + row['STMT_MON_03']) > row['CR_LIMIT'] else 0, axis=1)\n",
    "test['is_exceed_credit'] = test.apply(lambda row: 1 if (row['STMT_MON_01'] + row['STMT_MON_02'] + row['STMT_MON_03']) > row['CR_LIMIT'] else 0, axis =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## count live, closed loans\n",
    "liveLoan = [x for x in train.columns if 'SCRUB_LIVE' in x]\n",
    "closedLoan = [x for x in train.columns if 'SCRUB_CLOSED' in x]\n",
    "\n",
    "train['live_loan_count'] = train[liveLoan].sum(axis=1)\n",
    "train['closed_loan_count'] = train[closedLoan].sum(axis=1)\n",
    "\n",
    "test['live_loan_count'] = test[liveLoan].sum(axis=1)\n",
    "test['closed_loan_count'] = test[closedLoan].sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "txn_mon = [x for x in train.columns if 'TXN_MON' in x]\n",
    "txn_mon = txn_mon[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for c in txn_mon:\n",
    "    p = []\n",
    "    if 'CC_TXN' in c:\n",
    "        p.append(c)\n",
    "    train['total_credit_tran'] = train[p].sum(axis=1)\n",
    "    test['total_credit_tran'] = test[p].sum(axis=1)\n",
    "    \n",
    "for k in txn_mon:\n",
    "    j = []\n",
    "    if 'DC_TXN' in k:\n",
    "        j.append(c)\n",
    "    train['total_debit_tran'] = train[j].sum(axis=1)\n",
    "    test['total_debit_tran'] = test[j].sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(train.shape)\n",
    "print(test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### one hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "objCols = train.select_dtypes(include=['object']).columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "countDict = {}\n",
    "for x in objCols:\n",
    "    if train[x].nunique() > 2:\n",
    "        countDict[x] = train[x].nunique()\n",
    "        \n",
    "oneHotCols = list(countDict.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## check if object columns in both datasets have same unique values\n",
    "\n",
    "for x in oneHotCols:\n",
    "    if train[x].nunique() != test[x].nunique():\n",
    "        set_train = set(train[x].unique())\n",
    "        set_test = set(test[x].unique())\n",
    "        \n",
    "        remove_train = set_train - set_test\n",
    "        remove_test = set_test - set_train\n",
    "        \n",
    "        remove = remove_train.union(remove_test)\n",
    "        \n",
    "        def filter_cat(x):\n",
    "            if x in remove:\n",
    "                return np.nan\n",
    "            return x\n",
    "        \n",
    "        train[x] = train[x].map(filter_cat)\n",
    "        test[x] = test[x].map(filter_cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "oneHotCols = [x for x in oneHotCols if 'ZIP_CODE' not in x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "oneHot_train = pd.get_dummies(data=train[oneHotCols])\n",
    "oneHot_test = pd.get_dummies(data=test[oneHotCols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(oneHot_train.shape)\n",
    "print(oneHot_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = pd.concat([train, oneHot_train], axis=1)\n",
    "test = pd.concat([test, oneHot_test], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train.drop(oneHotCols, axis=1, inplace=True)\n",
    "test.drop(oneHotCols, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "del oneHot_test, oneHot_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(train.shape)\n",
    "print(test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### label encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for x in train.columns:\n",
    "    if x not in test.columns:\n",
    "        print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for x in test.columns:\n",
    "    if x not in train.columns:\n",
    "        print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train.drop(['NEFT_CC_CATEGORY_WEDDING','NEFT_DC_CATEGORY_RETURN'], axis=1, inplace=True)\n",
    "test.drop(['NEFT_CC_CATEGORY_CC_PAYMENT','NEFT_DC_CATEGORY_ADVANCE'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### remove columns with missing values - then label encode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "misCols = train.isnull().sum(axis=0)/train.shape[0]\n",
    "toremove = []\n",
    "\n",
    "for k, v in misCols.iteritems():\n",
    "    if v >= 0.96:\n",
    "        toremove.append(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(toremove)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "toremove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train.drop('OCCUP_ALL_NEW', axis=1, inplace=True)\n",
    "test.drop('OCCUP_ALL_NEW', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train.drop(toremove, inplace=True, axis=1)\n",
    "test.drop(toremove, inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for c in train.select_dtypes(include=['object']).columns:\n",
    "    if c not in ['CUSTOMER_ID','RESPONDERS']:\n",
    "        # print(c)\n",
    "        lbl = LabelEncoder()\n",
    "        lbl.fit(list(train[c].values) + list(test[c].values))\n",
    "        train[c] = lbl.transform(list(train[c].values))\n",
    "        test[c] = lbl.transform(list(test[c].values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train.fillna(-999, inplace=True)\n",
    "test.fillna(-999, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### normalise the values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train.fillna(-1, inplace=True)\n",
    "test.fillna(-1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mxsc = MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for c in train.columns:\n",
    "    if c not in ['RESPONDERS','CUSTOMER_ID']:\n",
    "        train[c] = mxsc.fit_transform(train[c])\n",
    "        test[c] = mxsc.fit_transform(test[c])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.model_selection import StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train['RESPONDERS'] = train['RESPONDERS'].replace(to_replace = {'Y':1, 'N':0})\n",
    "target = train['RESPONDERS']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### add pca features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Do PCA and get new features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feature_names = [x for x in train.columns if x not in ['CUSTOMER_ID','RESPONDERS']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dim_train = train[feature_names]\n",
    "dim_test = test[feature_names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rb = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dim_train = rb.fit_transform(dim_train)\n",
    "dim_test = rb.fit_transform(dim_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_comp = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### data has already been transformed\n",
    "dim_train = train[feature_names].copy()\n",
    "dim_test = test[feature_names].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tsvd = TruncatedSVD(n_components=n_comp, random_state=42)\n",
    "tsvd_train = tsvd.fit_transform(dim_train)\n",
    "tsvd_test = tsvd.transform(dim_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pca = PCA(n_components=n_comp, random_state=420)\n",
    "pca_train = pca.fit_transform(dim_train)\n",
    "pca_test = pca.transform(dim_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ica = FastICA(n_components=n_comp, random_state=2030)\n",
    "ica_train = ica.fit_transform(dim_train)\n",
    "ica_test = ica.transform(dim_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "grp = GaussianRandomProjection(n_components=n_comp, random_state=42)\n",
    "grp_train = grp.fit_transform(dim_train)\n",
    "grp_test = grp.transform(dim_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "srp = SparseRandomProjection(n_components=n_comp, random_state=42)\n",
    "srp_train = srp.fit_transform(dim_train)\n",
    "srp_test = srp.transform(dim_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tsne = TSNE(n_components=n_comp, random_state=42)\n",
    "tsne_train = tsne.fit_transform(dim_train)\n",
    "tsne_test = test.transform(dim_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in range(1, n_comp + 1):\n",
    "    train['pca_' + str(i)] = pca_train[:,i-1]\n",
    "    test['pca_' + str(i)] = pca_test[:,i-1]\n",
    "    \n",
    "    train['tsvd_' + str(i)] = tsvd_train[:,i-1]\n",
    "    test['tsvd_' + str(i)] = tsvd_test[:,i-1]\n",
    "    \n",
    "    train['ica_' + str(i)] = ica_train[:,i-1]\n",
    "    test['ica_' + str(i)] = ica_test[:,i-1]\n",
    "    \n",
    "    train['grp_' + str(i)] = grp_train[:,i-1]\n",
    "    test['grp_' + str(i)] = grp_test[:,i-1]\n",
    "    \n",
    "    train['srp_' + str(i)] = srp_train[:,i-1]\n",
    "    test['srp_' + str(i)] = srp_test[:,i-1]\n",
    "    \n",
    "    train['tsne_' + str(i)] = tsne_train[:,i-1]\n",
    "    test['tsne_' + str(i)] = tsne_test[:,i-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "del dim_train, dim_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(train.shape)\n",
    "print(test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train.to_pickle('submissions/train_standard.pkl')\n",
    "test.to_pickle('submissions/test_standard.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Single XGB Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGB 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feature_names = [x for x in train.columns if x not in ['CUSTOMER_ID','RESPONDERS']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_valid, y_train, y_valid = train_test_split(train, target, test_size = 0.3, stratify = target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "params = {\"objective\": \"binary:logistic\",\n",
    "          \"booster\": \"gbtree\",\n",
    "          \"nthread\": 4,\n",
    "          \"eta\": 0.1, # 0.1\n",
    "          \"max_depth\": 5, # 7\n",
    "          \"subsample\": 0.8,\n",
    "          \"colsample_bytree\": 0.4,\n",
    "          \"min_child_weight\": 2**3,\n",
    "          \"seed\": 2016, \n",
    "          \"tree_method\": \"exact\",\n",
    "         \"eval_metric\":\"auc\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#dtrain = xgb.DMatrix(X_train[feature_names], y_train, missing=-999)\n",
    "#dvalid = xgb.DMatrix(X_valid[feature_names], y_valid, missing=-999)\n",
    "#dtest = xgb.DMatrix(test[feature_names], missing=-999)\n",
    "\n",
    "## normalised data\n",
    "dtrain = xgb.DMatrix(X_train[feature_names], y_train)\n",
    "dvalid = xgb.DMatrix(X_valid[feature_names], y_valid)\n",
    "dtest = xgb.DMatrix(test[feature_names])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "watchlist = [(dtrain, 'train'),(dvalid, 'valid')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "clf1 = xgb.train(params, dtrain, num_boost_round=1000, evals=watchlist, maximize=True, verbose_eval=20, early_stopping_rounds=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "xgb.plot_importance(clf1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## important features sorted\n",
    "imp_feats = sorted(clf1.get_fscore(), key=lambda x: x[1], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "preds1 = clf1.predict(dtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "sub = pd.read_csv('sample_submission_ROqqAAN.csv')\n",
    "sub['CUSTOMER_ID'] = test['CUSTOMER_ID']\n",
    "sub['RESPONDERS'] = preds1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sub.to_csv('submissions/xgb_single_four.csv', index=False) ## 0.642 / 89.09"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sub.to_csv('submissions/xgb_single_five.csv', index=False) ## 66 / 89.19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sub.to_csv('submissions/xgb_single_six.csv', index=False) ### 0.65.66 LB / 89.54"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## trying rank average\n",
    "sub['ranks'] = np.argsort(sub['RESPONDERS'])+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "maxrank = np.max(sub['ranks'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sub['ranks'] = sub['ranks'] / maxrank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sub.drop('RESPONDERS', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sub.rename(columns={'ranks':'RESPONDERS'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sub.to_csv('submissions/rank_average_xgb_four.csv', index=False) # 0.10273"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGB with imp. features from previous model - Not good"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(imp_feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "top_100 = imp_feats[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dtrain = xgb.DMatrix(X_train[top_100], y_train, missing=-999)\n",
    "dvalid = xgb.DMatrix(X_valid[top_100], y_valid, missing=-999)\n",
    "dtest = xgb.DMatrix(test[top_100], missing=-999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "params = {\"objective\": \"binary:logistic\",\n",
    "          \"booster\": \"gbtree\",\n",
    "          \"nthread\": 4,\n",
    "          \"eta\": 0.1, # 0.1\n",
    "          \"max_depth\": 5, # 7\n",
    "          \"subsample\": 0.8,\n",
    "          \"colsample_bytree\": 0.8,\n",
    "          \"min_child_weight\": 2,\n",
    "          \"seed\": 2016, \n",
    "          \"tree_method\": \"exact\",\n",
    "         \"eval_metric\":\"auc\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "watchlist = [(dtrain, 'train'),(dvalid, 'valid')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "clf1 = xgb.train(params, dtrain, num_boost_round=10000, evals=watchlist, maximize=True, verbose_eval=20, early_stopping_rounds=40)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By removing features, AUC is dropping."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGB with Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## normalised data\n",
    "dtrain = xgb.DMatrix(X_train[feature_names], y_train)\n",
    "dvalid = xgb.DMatrix(X_valid[feature_names], y_valid)\n",
    "dtest = xgb.DMatrix(test[feature_names])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "params = {\"objective\": \"binary:logistic\",\n",
    "          \"booster\": \"gblinear\",\n",
    "          \"nthread\": 4,\n",
    "          \"alpha\": 2**3,\n",
    "          \"lambda\": 2**4,\n",
    "         \"eval_metric\":\"auc\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "watchlist = [(dtrain, 'train'),(dvalid, 'valid')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "clf1 = xgb.train(params, dtrain, num_boost_round=10000, evals=watchlist, maximize=True, verbose_eval=20, early_stopping_rounds=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "preds1 = clf1.predict(dtest)\n",
    "sub = pd.read_csv('sample_submission_ROqqAAN.csv')\n",
    "sub['CUSTOMER_ID'] = test['CUSTOMER_ID']\n",
    "sub['RESPONDERS'] = preds1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sub.to_csv('submissions/xgb_logistic_eight.csv', index=False) # 0.59038 / # 0.8475"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## submit average of xgb single five and logistic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xgb_five = pd.read_csv('submissions/xgb_single_five.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xgb_five['New_Responders'] = sub['RESPONDERS']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "xgb_five.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xgb_five['average'] = xgb_five.loc[:,['RESPONDERS','New_Responders']].mean(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sub = pd.read_csv('sample_submission_ROqqAAN.csv')\n",
    "sub['CUSTOMER_ID'] = test['CUSTOMER_ID']\n",
    "sub['RESPONDERS'] = xgb_five['average']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sub.to_csv('submissions/xgb_best_logistic_average.csv', index=False) ## 0.6606 best score."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGB SINGLE MODEL WITH WEIGHTS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGB 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train['weights'] = train['RESPONDERS'].map(lambda x: 0.8 if x == 1 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feature_names2 = [x for x in train.columns if x not in ['CUSTOMER_ID','RESPONDERS']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_valid, y_train, y_valid = train_test_split(train, target, test_size = 0.3, stratify = target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "params = {\"objective\": \"binary:logistic\",\n",
    "          \"booster\": \"gbtree\",\n",
    "          \"nthread\": 4,\n",
    "          \"eta\": 0.1, # 0.1\n",
    "          \"max_depth\": 5, # 7\n",
    "          \"subsample\": 0.8,\n",
    "          \"colsample_bytree\": 0.4,\n",
    "          \"min_child_weight\": 2**3,\n",
    "          \"seed\": 2016, \n",
    "          \"tree_method\": \"exact\",\n",
    "         \"eval_metric\":\"auc\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dtrain = xgb.DMatrix(X_train[feature_names2], y_train, weight=weights)\n",
    "dvalid = xgb.DMatrix(X_valid[feature_names2], y_valid, weight=weights)\n",
    "dtest = xgb.DMatrix(test[feature_names])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "watchlist = [(dtrain, 'train'),(dvalid, 'valid')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "clf1 = xgb.train(params, dtrain, num_boost_round=10000, evals=watchlist, maximize=True, verbose_eval=20, early_stopping_rounds=40)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "default params are giving lower score than tuned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EXTRA TREES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train.drop('weights', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import roc_auc_score, make_scorer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "et = ExtraTreesClassifier(n_estimators=100, \n",
    "                          criterion = 'entropy', \n",
    "                          max_depth=10, \n",
    "                          max_features='auto',\n",
    "                          min_samples_split = 3,\n",
    "                          n_jobs = -1,\n",
    "                         random_state = 4343)\n",
    "                         #class_weight = {0:1, 1:10})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "feature_names2 = [x for x in feature_names2 if 'weights' not in x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cross_val_score(et, train[feature_names2], target, scoring=make_scorer(roc_auc_score), cv = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### XGB Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "param_dart = {'booster': 'dart',\n",
    "         'max_depth': 5, 'learning_rate': 0.1,\n",
    "         'objective': 'binary:logistic',\n",
    "            'sample_type': 'uniform',\n",
    "         'normalize_type': 'tree',\n",
    "         'rate_drop': 0.1,\n",
    "         'skip_drop': 0.5,\n",
    "             'eval_metric':'auc'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "param_forest = {'booster': 'dart',\n",
    "         'max_depth': 5, 'learning_rate': 0.1,\n",
    "         'objective': 'binary:logistic',\n",
    "            'sample_type': 'uniform',\n",
    "         'normalize_type': 'forest',\n",
    "         'rate_drop': 0.2,\n",
    "         'skip_drop': 0.6,\n",
    "             'eval_metric':'auc'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#dtrain = xgb.DMatrix(X_train[feature_names], y_train, missing=-999)\n",
    "#dvalid = xgb.DMatrix(X_valid[feature_names], y_valid, missing=-999)\n",
    "#dtest = xgb.DMatrix(test[feature_names], missing=-999)\n",
    "\n",
    "## normalised data\n",
    "dtrain = xgb.DMatrix(X_train[feature_names], y_train)\n",
    "dvalid = xgb.DMatrix(X_valid[feature_names], y_valid)\n",
    "dtest = xgb.DMatrix(test[feature_names])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "watchlist = [(dtrain, 'train'),(dvalid, 'valid')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "clf1 = xgb.train(param_forest, dtrain, num_boost_round=1000, evals=watchlist, maximize=True, verbose_eval=20, early_stopping_rounds=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "preds1 = clf1.predict(dtest)\n",
    "sub = pd.read_csv('sample_submission_ROqqAAN.csv')\n",
    "sub['CUSTOMER_ID'] = test['CUSTOMER_ID']\n",
    "sub['RESPONDERS'] = preds1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sub.to_csv('submissions/xgb_randomforest.csv', index=False) ## CV - 89.3244 | LB 0.651 ## type == 'tree'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sub.to_csv('submissions/xgb_randomforest_forest.csv', index=False) ## CV - 89.3427 | LB 0.64629 ## type == 'forest'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stacker - Random Forest - with scaled data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nfolds = 10\n",
    "skf = StratifiedKFold(n_splits=nfolds, shuffle=True, random_state=9087)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "param_dart = {'booster': 'dart',\n",
    "         'max_depth': 5, 'learning_rate': 0.1,\n",
    "         'objective': 'binary:logistic',\n",
    "            'sample_type': 'uniform',\n",
    "         'normalize_type': 'tree',\n",
    "         'rate_drop': 0.1,\n",
    "         'skip_drop': 0.5,\n",
    "             'eval_metric':'auc'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "oof_train = pd.DataFrame({'CUSTOMER_ID':train['CUSTOMER_ID'], 'RESPONDERS':0})\n",
    "allpredictions = pd.DataFrame()\n",
    "score = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## without upscaling\n",
    "\n",
    "increase = True\n",
    "for i, (train_index, test_index) in enumerate(skf.split(train, target)):\n",
    "    print('Fold %d/%d'%(i+1, nfolds))\n",
    "    X_train, X_valid = train.iloc[train_index], train.iloc[test_index]\n",
    "    y_train, y_valid = target.iloc[train_index], target.iloc[test_index]\n",
    "    \n",
    "#     if increase:\n",
    "#         pos = pd.Series(target == 1)\n",
    "\n",
    "#         X_train = pd.concat([X_train, X_train[pos]], axis=0)\n",
    "#         y_train = pd.concat([y_train, y_train.loc[pos]], axis=0)\n",
    "        \n",
    "#         idx = np.arange(len(X_train))\n",
    "#         np.random.shuffle(idx)\n",
    "#         X_train = X_train.iloc[idx]\n",
    "#         y_train = y_train.iloc[idx]\n",
    "    \n",
    "    dtrain = xgb.DMatrix(X_train[feature_names], label=y_train)\n",
    "    dvalid = xgb.DMatrix(X_valid[feature_names], label=y_valid)\n",
    "    \n",
    "    watchlist = [(dtrain, 'train'),(dvalid,'valid')]\n",
    "    \n",
    "    clf = xgb.train(param_dart,\n",
    "                    dtrain,\n",
    "                    num_boost_round=10000,\n",
    "                    evals=watchlist,\n",
    "                    early_stopping_rounds=40,\n",
    "                    verbose_eval=20,\n",
    "                    maximize = True)\n",
    "    \n",
    "    pred1 = clf.predict(dvalid)\n",
    "    oof_train.loc[test_index, 'RESPONDERS'] = pred1\n",
    "    \n",
    "    scr = roc_auc_score(y_valid, pred1)\n",
    "    dtest = xgb.DMatrix(test[feature_names])\n",
    "    preds2 = clf.predict(dtest)\n",
    "    \n",
    "    allpredictions['p'+str(i)] = preds2\n",
    "    score.append(scr)\n",
    "    \n",
    "    del X_train, X_valid, y_train, y_valid, clf, pred1, preds2, scr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.mean(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "oof_train.to_csv('submissions/oof_preds/xgb_train1.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "allpredictions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sub = pd.read_csv('sample_submission_ROqqAAN.csv')\n",
    "sub['CUSTOMER_ID'] = test['CUSTOMER_ID']\n",
    "sub['RESPONDERS'] = allpredictions.mean(axis=1).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sub.to_csv('submissions/xgb_bagging_seven.csv', index=False) # 0.58"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGB 2 - remove zero variance features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## remove zero variance columns\n",
    "var_check = pd.DataFrame(columns=['name','variance'])\n",
    "\n",
    "for i, c in enumerate(train.columns):\n",
    "    if c not in ['CUSTOMER_ID','RESPONDERS']:\n",
    "        var_check.loc[i, 'name'] = c\n",
    "        var_check.loc[i, 'variance'] = train[c].var()\n",
    "        \n",
    "var_check.sort_values('variance', ascending=True).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cols_to_use = var_check[var_check['variance'] > 1]['name'].tolist() ## remove columns with variance lesser than zero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "params = {\"objective\": \"binary:logistic\",\n",
    "          \"booster\": \"gbtree\",\n",
    "          \"nthread\": 4,\n",
    "          \"eta\": 0.1,\n",
    "          \"max_depth\": 5,\n",
    "          \"subsample\": 0.8,\n",
    "          \"colsample_bytree\": 0.3,\n",
    "          \"min_child_weight\": 0,\n",
    "          \"seed\": 2017, \n",
    "          \"tree_method\": \"exact\",\n",
    "         \"eval_metric\":\"auc\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dtrain = xgb.DMatrix(X_train[cols_to_use], y_train, missing=-1)\n",
    "dvalid = xgb.DMatrix(X_valid[cols_to_use], y_valid, missing=-1)\n",
    "dtest = xgb.DMatrix(test[cols_to_use], missing=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "watchlist = [(dtrain, 'train'),(dvalid, 'valid')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clf1 = xgb.train(params, dtrain, num_boost_round=10000, evals=watchlist, maximize=True, verbose_eval=20, early_stopping_rounds=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "preds1 = clf1.predict(dtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sub = pd.read_csv('sample_submission_ROqqAAN.csv')\n",
    "sub['CUSTOMER_ID'] = test['CUSTOMER_ID']\n",
    "sub['RESPONDERS'] = preds1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sub.to_csv('submissions/xgb_single_three.csv', index=False) ## 54 - score dropping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGB BAGGED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "oof_train = pd.DataFrame({'CUSTOMER_ID':train['CUSTOMER_ID'], 'RESPONDERS':0})\n",
    "allpredictions = pd.DataFrame()\n",
    "score = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "increase = True\n",
    "for i, (train_index, test_index) in enumerate(skf.split(train, target)):\n",
    "    print('Fold %d/%d'%(i+1, nfolds))\n",
    "    X_train, X_valid = train.iloc[train_index], train.iloc[test_index]\n",
    "    y_train, y_valid = target.iloc[train_index], target.iloc[test_index]\n",
    "    \n",
    "    if increase:\n",
    "        pos = pd.Series(target == 1)\n",
    "\n",
    "        X_train = pd.concat([X_train, X_train[pos]], axis=0)\n",
    "        y_train = pd.concat([y_train, y_train.loc[pos]], axis=0)\n",
    "        \n",
    "        idx = np.arange(len(X_train))\n",
    "        np.random.shuffle(idx)\n",
    "        X_train = X_train.iloc[idx]\n",
    "        y_train = y_train.iloc[idx]\n",
    "    \n",
    "    dtrain = xgb.DMatrix(X_train[feature_names], label=y_train, missing=-1)\n",
    "    dvalid = xgb.DMatrix(X_valid[feature_names], label=y_valid, missing = -1)\n",
    "    \n",
    "    watchlist = [(dtrain, 'train'),(dvalid,'valid')]\n",
    "    \n",
    "    clf = xgb.train(params,\n",
    "                    dtrain,\n",
    "                    num_boost_round=10000,\n",
    "                    evals=watchlist,\n",
    "                    early_stopping_rounds=40,\n",
    "                    verbose_eval=20,\n",
    "                    maximize = True)\n",
    "    \n",
    "    pred1 = clf.predict(dvalid)\n",
    "    oof_train.loc[test_index, 'RESPONDERS'] = pred1\n",
    "    \n",
    "    scr = roc_auc_score(y_valid, pred1)\n",
    "    dtest = xgb.DMatrix(test[feature_names], missing= - 1)\n",
    "    preds2 = clf.predict(dtest)\n",
    "    \n",
    "    allpredictions['p'+str(i)] = preds2\n",
    "    score.append(scr)\n",
    "    \n",
    "    del X_train, X_valid, y_train, y_valid, clf, pred1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.mean(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "oof_train.to_csv('submissions/oof_preds/xgb_train1.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "allpredictions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sub = pd.read_csv('sample_submission_ROqqAAN.csv')\n",
    "sub['CUSTOMER_ID'] = test['CUSTOMER_ID']\n",
    "sub['RESPONDERS'] = allpredictions.mean(axis=1).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sub.to_csv('submissions/xgb_bagging_seven.csv', index=False) # 0.58"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
